# -*- coding: utf-8 -*-
"""DS_Designed.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11X6D2HwOkW53-t5DvjEGLnJj4gp6LsV1
"""

from google.colab import drive
drive.mount('/content/gdrive')
#4/TwFbyEdEj30EgQsCQNwt9kaRBvJuXHvNcVxozNnxZWS8qOFORLhOoIY

!pip install Pillow==4.0.0
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True
# import matplotlib.pyplot as plt
# import matplotlib.image as mpimg
# from tensorflow.keras import layers
# from tensorflow.keras import Model
# import os, tensorflow as tf
# import pprint
# from tensorflow.keras.preprocessing.image import ImageDataGenerator
# from tensorflow.keras.optimizers import RMSprop
# import keras
# import numpy as np
# from keras.applications import vgg16, inception_v3, resnet50, mobilenet
# !pip install h5py pyyaml
# !pip install tf_nightly

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale = 1./255,
    rotation_range = 40,
    width_shift_range = 0.2,
    height_shift_range = 0.2,
    shear_range = 0.2,
    zoom_range = 0.2,
    horizontal_flip = True)

# Note that the validation data should not be augmented!
test_datagen = ImageDataGenerator(rescale = 1./255)

# Flow training images in batches of 32 using train_datagen generator
train_generator = train_datagen.flow_from_directory(
        "/content/gdrive/My Drive/cervical_cancer_data/train",  # This is the source directory for training images
        target_size = (150, 150),  # All images will be resized to 150x150
        batch_size = 64,
        # Since we use binary_crossentropy loss, we need binary labels
        class_mode = 'categorical')

# Flow validation images in batches of 32 using test_datagen generator
validation_generator = test_datagen.flow_from_directory(
        "/content/gdrive/My Drive/cervical_cancer_data/val",
        target_size = (150, 150),
        batch_size = 64,
        class_mode = 'categorical')

from tensorflow.keras import layers
from tensorflow.keras import Model, Input
import tensorflow as tf
import keras

from tensorflow.keras.applications import vgg16, inception_v3, resnet50, mobilenet
img_input = layers.Input(shape = (150, 150, 3))


x = layers.Conv2D(16, 3, activation = 'relu')(img_input)
x = layers.MaxPooling2D(2)(x)
x = layers.Conv2D(32, 3, activation='relu')(x)
x = layers.MaxPooling2D(2)(x)

x = layers.Convolution2D(64, 3, activation = 'relu')(x)
x = layers.MaxPooling2D(2)(x)

x = layers.Flatten()(x)

x = layers.Dense(512, activation = 'relu')(x)

x = layers.Dropout(0.5)(x)

output = layers.Dense(3, activation = 'sigmoid')(x)

model = Model(img_input, output)
model.summary()

import os
tpu_model = tf.contrib.tpu.keras_to_tpu_model(
    model,
    strategy=tf.contrib.tpu.TPUDistributionStrategy(
        tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
    )
)
tpu_model.compile(
    optimizer=tf.train.AdamOptimizer(learning_rate=1e-3, ),
    loss=tf.keras.losses.categorical_crossentropy,
    metrics=['categorical_accuracy']
)

history = tpu_model.fit_generator(
      train_generator,
      steps_per_epoch = 100,  # 2000 images = batch_size * steps
      epochs = 15,
      validation_data = validation_generator,
      validation_steps = 50,  # 1000 images = batch_size * steps
      verbose = 2)

tpu_model.save('designed.h5')

import matplotlib.pyplot as plt
print(history.history.keys())
acc = history.history['categorical_accuracy']
val_acc = history.history['val_categorical_accuracy']

# Retrieve a list of list results on training and test data
# sets for each training epoch
loss = history.history['loss']
val_loss = history.history['val_loss']

# Get number of epochs
epochs = range(len(acc))

# Plot training and validation accuracy per epoch
plt.plot(epochs, acc)
plt.plot(epochs, val_acc)
plt.title('Training and validation accuracy')

plt.figure()

# Plot training and validation loss per epoch
plt.plot(epochs, loss)
plt.plot(epochs, val_loss)
plt.title('Training and validation loss')

Y_pred = tpu_model.predict_generator(validation_generator, 64)
y_pred = np.argmax(Y_pred, axis=1)
print('Confusion Matrix')
print(confusion_matrix(validation_generator.classes, y_pred))
print('Classification Report')
target_names = ['Type_1', 'Type_2', 'Type_3']
print(classification_report(validation_generator.classes, y_pred, target_names=target_names))

from tensorflow import keras

new_model = keras.models.load_model('designed.h5')
new_model.summary()

new_model.compile(
    optimizer=tf.train.AdamOptimizer(learning_rate=1e-3, ),
    loss=tf.keras.losses.categorical_crossentropy,
    metrics=['categorical_accuracy']
)